{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_search",
      "provenance": [],
      "authorship_tag": "ABX9TyPcLBzPPcYdoUxaUiNB/rTj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Achuttarsing/Slow-Fast-pytorch-implementation/blob/master/semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo4UC17fNLEF"
      },
      "source": [
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "import ast\n",
        "def read_csv_shot(path):\n",
        "    s = pd.read_csv(path, index_col=0)\n",
        "    for feature_name in ['detected_things','detected_things_more','talking_persons_in_scene','talking_persons_in_shot','detected_people']:\n",
        "        if feature_name in s.columns:\n",
        "            s[feature_name] = s[feature_name].fillna(\"[]\")\n",
        "            s[feature_name] = s[feature_name].apply(ast.literal_eval)\n",
        "    return s\n",
        "\n",
        "import clip\n",
        "import torch\n",
        "\n",
        "import datetime\n",
        "from IPython.core.display import HTML\n",
        "import time\n",
        "\n",
        "def search_video(search_query, return_urls=False, top_n=10):\n",
        "    start = time.time()\n",
        "\n",
        "    # Encode and normalize the search query using CLIP\n",
        "    with torch.no_grad():\n",
        "        text_features = model.encode_text(clip.tokenize(search_query).to(device))\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # Compute the similarity between the search query and each frame using the Cosine similarity\n",
        "    similarities = (100.0 * VIDEO_FEATURES.float() @ text_features.T)\n",
        "    values, best_photo_idx = similarities.topk(top_n, dim=0)\n",
        "    best_photo_idx = [x.item() for x in best_photo_idx]\n",
        "\n",
        "    computing_time = round(time.time() - start, 4)\n",
        "    print(\"computing time =\",computing_time,\"sec\")\n",
        "\n",
        "    if return_urls == False:\n",
        "        EXPORT = {}\n",
        "        for sim, frame_id in zip(values, best_photo_idx):\n",
        "            mask = (LENS <= frame_id)\n",
        "            id = MOVIE_IDS[mask.sum() - 1]\n",
        "            if id not in EXPORT: \n",
        "                EXPORT[id] = {}\n",
        "                EXPORT[id]['shot_ids'] = []\n",
        "                EXPORT[id]['similarity_scores'] = []\n",
        "\n",
        "            EXPORT[id]['shot_ids'].append(int((frame_id - LENS[mask][-1])+1))\n",
        "            EXPORT[id]['similarity_scores'].append(sim.item())\n",
        "\n",
        "        return EXPORT, computing_time\n",
        "\n",
        "    else:\n",
        "        EXPORT = {}\n",
        "        URLS = []\n",
        "        PROBAS = []\n",
        "        for sim, frame_id in zip(values, best_photo_idx):\n",
        "            mask = (LENS <= frame_id)\n",
        "            id = MOVIE_IDS[mask.sum() - 1]\n",
        "            if id not in EXPORT: \n",
        "                EXPORT[id] = {}\n",
        "                EXPORT[id]['shot_ids'] = []\n",
        "                EXPORT[id]['similarity_scores'] = []\n",
        "\n",
        "            EXPORT[id]['shot_ids'].append(int((frame_id - LENS[mask][-1])+1))\n",
        "            EXPORT[id]['similarity_scores'].append(sim.item())\n",
        "            URLS.append('https://ateliernumerique.ensci.com/oucipo/data/PROCESSED_MOVIES/'+MOVIE_TITLES[mask.sum() - 1]+'/image_shots/shot-'+str(EXPORT[id]['shot_ids'][-1]).zfill(4)+'-01.jpg')\n",
        "            PROBAS.append(sim.item())\n",
        "\n",
        "        return EXPORT, computing_time, URLS, PROBAS\n",
        "\n",
        "# Load the open CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from ftplib import FTP\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import os, json, random\n",
        "\n",
        "ftp = FTP(host='ateliernumerique.ensci.com', user='ftp-oucipo-data', passwd='oucipo')  # connect to host, default port\n",
        "ftp.cwd('/data/PROCESSED_MOVIES')\n",
        "PROCESSED_MOVIES = ftp.nlst()\n",
        "\n",
        "VIDEO_FEATURES = {}\n",
        "MOVIE_TITLES = []\n",
        "for FOLDER in tqdm(PROCESSED_MOVIES, desc='Loading clip encodings'):\n",
        "    try:\n",
        "        ftp.cwd('/data/PROCESSED_MOVIES/'+FOLDER)\n",
        "\n",
        "        # load shots\n",
        "        ftp.retrbinary(\"RETR shots.csv\" ,open('shots.csv', 'wb').write)\n",
        "        shot = read_csv_shot('shots.csv')\n",
        "        MOVIE_ID = str(shot.at[1,'movie_id']).zfill(7)\n",
        "\n",
        "        ftp.retrbinary(\"RETR clip_encoding\" ,open('clip_encoding','wb').write)\n",
        "        VIDEO_FEATURES[MOVIE_ID] = torch.load(\"clip_encoding\",map_location=torch.device('cpu'))\n",
        "        MOVIE_TITLES.append(FOLDER)\n",
        "    except:\n",
        "        print(\"cant process :\",FOLDER)\n",
        "\n",
        "LENS = np.array([0] + [VIDEO_FEATURES[x].shape[0] for x in VIDEO_FEATURES]).cumsum()\n",
        "MOVIE_IDS = [x for x in VIDEO_FEATURES]\n",
        "VIDEO_FEATURES = torch.cat([VIDEO_FEATURES[x] for x in VIDEO_FEATURES])\n",
        "\n",
        "MOVIE_TITLES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye9yyl96NUw4"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "from flask import Flask\n",
        "import simplejson\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return '''<!doctype html>\n",
        "\t<html lang=\"fr\">\n",
        "\t\t<head>\n",
        "\t\t\t<meta charset=\"utf-8\">\n",
        "\t\t\t<title>Le formulaire</title>\n",
        "\t\t</head>\n",
        "\t\t<body>\n",
        "\t\t\t<form action=\"/resultat\" method=\"post\">\n",
        "\t\t\t\t\t<label>text input</label> : <input type=\"text\" name=\"text_input\" />\n",
        "\t\t\t\t\t<input type=\"submit\" value=\"Envoyer\" />\n",
        "\t\t\t</form>\n",
        "\t\t</body>\n",
        "\t</html>'''\n",
        "  \n",
        "\n",
        "@app.route('/resultat',methods = ['POST'])\n",
        "def resultat():\n",
        "    result = request.form\n",
        "    text_input = result['text_input']\n",
        "    print(\"REQUEST =\",text_input)\n",
        "    EXPORT, computing_time, URLS, PROBAS = search_video(text_input, return_urls=True, top_n=1000)\n",
        "    return simplejson.dumps(EXPORT, ignore_nan=True)\n",
        "    #return \"<h1> text input : \\\"\"+text_input+\"\\\"\"+\"</h1>\"+ \"<h4>\" + \"computing time = \" + str(computing_time) +\" sec\" +\"</h4>\" + ' '.join([\"<img src=\\\"\"+t+\"\\\">\"+str(PROBAS[c]) for c,t in enumerate(URLS)])\n",
        "\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}